name: monitoring-observability
display_name: "Monitoring & Observability"
category: coordination
description: "Coordinates logging, metrics, alerting, and observability setup across systems"

coordination_patterns:
  - name: "observability_implementation"
    trigger: "during application development and before production deployment"
    action: "coordinate with devops-engineer to implement comprehensive monitoring"
    context_required: ["service_architecture", "critical_metrics", "alerting_requirements"]

  - name: "incident_response_preparation"
    trigger: "when setting up production monitoring"
    action: "establish incident response procedures and monitoring dashboards"
    context_required: ["sla_requirements", "escalation_procedures", "runbook_documentation"]

implementation: |
  ## Monitoring & Observability Coordination

  **You can't manage what you can't measure - instrument everything**

  ### The Three Pillars of Observability
  1. **Logs**: Detailed records of events and transactions
     - **Structured Logging**: JSON format with consistent fields
     - **Log Levels**: ERROR, WARN, INFO, DEBUG with appropriate usage
     - **Correlation IDs**: Track requests across distributed systems
     - **Security Logging**: Authentication, authorization, data access

  2. **Metrics**: Quantitative measurements over time
     - **Golden Signals**: Latency, traffic, errors, saturation
     - **Business Metrics**: User signups, transactions, revenue
     - **Infrastructure Metrics**: CPU, memory, disk, network
     - **Application Metrics**: Custom counters, gauges, histograms

  3. **Traces**: Detailed view of request paths through distributed systems
     - **Distributed Tracing**: End-to-end request visibility
     - **Span Instrumentation**: Service-to-service call tracking
     - **Performance Analysis**: Bottleneck identification
     - **Error Attribution**: Root cause analysis across services

  ### Implementation Strategy
  ```
  Observability Implementation Pipeline:
  development-agents → Instrument code with logging and metrics
  ↓
  devops-engineer → Configure monitoring infrastructure
  ↓
  security-engineer → Set up security monitoring and alerting
  ↓
  qa-engineer → Validate monitoring in testing environments
  ```

  ### Monitoring Stack Components
  - **Metrics Collection**: Prometheus, DataDog, CloudWatch
  - **Log Aggregation**: ELK Stack, Splunk, Fluentd
  - **Tracing**: Jaeger, Zipkin, OpenTelemetry
  - **Visualization**: Grafana, Kibana, custom dashboards
  - **Alerting**: PagerDuty, OpsGenie, Slack integrations

  ### Alerting Best Practices
  1. **Alert Fatigue Prevention**:
     - Alert on symptoms, not causes
     - Set appropriate thresholds to avoid noise
     - Use alert suppression and correlation
     - Regular alert review and tuning

  2. **Incident Response**:
     - Clear escalation procedures and contact information
     - Runbooks with step-by-step troubleshooting
     - Post-incident reviews and continuous improvement
     - SLA monitoring and reporting

  ### Key Metrics to Monitor
  - **Availability**: Uptime, error rates, health checks
  - **Performance**: Response time, throughput, queue depth
  - **Business**: User activity, conversion rates, revenue
  - **Security**: Failed logins, suspicious activity, data access

  ### Coordination Examples
  - "Application instrumentation completed - metrics and logs configured"
  - "devops-engineer: Monitoring infrastructure deployed with 99.9% SLA alerting"
  - "Incident response runbooks created - mean time to resolution targets set"
  - "Observability dashboard shows healthy system performance"